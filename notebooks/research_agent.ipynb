{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.models import MODEL\n",
    "from src.utils.helpers import get_today_str, get_prompt_template\n",
    "from src.deep_research_agent.state import AgentState,AgentInputState\n",
    "from pydantic import BaseModel, Field\n",
    "from src.config import ROOT_DIR\n",
    "from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "import os\n",
    "from typing import Literal\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from src.utils.notebook_utils import format_messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccd042",
   "metadata": {},
   "source": [
    "# Scoping Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClarifyWithUser(BaseModel):\n",
    "    \"\"\"Schema for user clarification decision and questions.\"\"\"\n",
    "    \n",
    "    need_clarification: bool = Field(\n",
    "        description=\"Whether the user needs to be asked a clarifying question.\",\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"A question to ask the user to clarify the report scope\",\n",
    "    )\n",
    "    verification: str = Field(\n",
    "        description=\"Verify message that we will start research after the user has provided the necessary information.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class ResearchQuestion(BaseModel):\n",
    "    \"\"\"Schema for structured research brief generation.\"\"\"\n",
    "    \n",
    "    research_brief: str = Field(\n",
    "        description=\"A research question that will be used to guide the research.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742afb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up structured output model\n",
    "CLARIFY_WITH_USER_PROMPT_TEMPLATE = get_prompt_template(os.path.join(ROOT_DIR, \"src/deep_research_agent/prompts/clarify_with_user_instruction.jinja\"))\n",
    "WRITE_RESEARCH_BRIEF_PROMPT_TEMPLATE = get_prompt_template(os.path.join(ROOT_DIR, \"src/deep_research_agent/prompts/write_research_brief_from_messages.jinja\"))\n",
    "\n",
    "def clarify_with_user(state: AgentState) -> Command[Literal[\"write_research_brief\", END]]:\n",
    "    \"\"\"\n",
    "    Determine if the user's request contains sufficient information to proceed with research.\n",
    "    \n",
    "    Uses structured output to make deterministic decisions and avoid hallucination.\n",
    "    Routes to either research brief generation or ends with a clarification question.\n",
    "    \"\"\"\n",
    "    structured_output_model = MODEL.with_structured_output(ClarifyWithUser)\n",
    "    # Invoke the model with clarification instructions\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=CLARIFY_WITH_USER_PROMPT_TEMPLATE.render(\n",
    "            messages=get_buffer_string(messages=state[\"messages\"]), \n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Alternately can also go to a dedicated node to ask human for clarification question\n",
    "    # Route based on clarification need\n",
    "    if response.need_clarification:\n",
    "        return Command(\n",
    "            goto=END, \n",
    "            update={\"messages\": [AIMessage(content=response.question)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"write_research_brief\", \n",
    "            update={\"messages\": [AIMessage(content=response.verification)]}\n",
    "        )\n",
    "\n",
    "\n",
    "def write_research_brief(state: AgentState):\n",
    "    \"\"\"\n",
    "    Transform the conversation history into a comprehensive research brief.\n",
    "    \n",
    "    Uses structured output to ensure the brief follows the required format\n",
    "    and contains all necessary details for effective research.\n",
    "    \"\"\"\n",
    "    # Set up structured output model\n",
    "    structured_output_model = MODEL.with_structured_output(ResearchQuestion)\n",
    "    \n",
    "    # Generate research brief from conversation history\n",
    "    response = structured_output_model.invoke([\n",
    "        HumanMessage(content=WRITE_RESEARCH_BRIEF_PROMPT_TEMPLATE.render(\n",
    "            messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Update state with generated research brief and pass it to the supervisor\n",
    "    return {\n",
    "        \"research_brief\": response.research_brief,\n",
    "        \"supervisor_messages\": [HumanMessage(content=f\"{response.research_brief}.\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState,input_schema=AgentInputState)\n",
    "builder.add_node( \"clarify_with_user\",clarify_with_user)\n",
    "builder.add_node(\"write_research_brief\",write_research_brief)\n",
    "builder.add_edge(START, \"clarify_with_user\")\n",
    "builder.add_edge(\"write_research_brief\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "scope_graph = builder.compile(checkpointer=checkpointer)\n",
    "display(Image(scope_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09ce2c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = scope_graph.invoke({\"messages\": [HumanMessage(content=\"I want to research the best coffee shops in San Francisco.\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scope_graph.invoke({\"messages\": [HumanMessage(content=\"I don't have any details please proceed\")]}, config=thread)\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f84115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendeepresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
